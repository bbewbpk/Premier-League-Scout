{"cells":[{"cell_type":"markdown","metadata":{},"source":["# EPL 23/34 Player Dataset\n","\n","This notebook is created for study and as part of a personal project related to the English Premier League (EPL).\n","\n","## Overview\n","\n","The dataset provided in this notebook includes information on players who participated in EPL 23/34. The data is formatted as an SQL file for easy integration into databases.\n","\n","## Data Source\n","\n","The data is collected from the official [Premier League website](https://www.premierleague.com/), a reliable source for up-to-date information on EPL teams and players.\n","\n","## Purpose\n","\n","The primary goals of this notebook are:\n","\n","1. **Study**: Understand and analyze player data in the context of the EPL 23/34 season.\n","2. **Personal Project**: Contribute to a personal project related to the English Premier League.\n","\n","## Contents\n","\n","- **Data Collection**: Player information is scraped from the Premier League website, including details such as name, position, date of birth, and team affiliation.\n","- **SQL Format**: The collected data is formatted into SQL queries for easy integration into database systems.\n","\n","## Instructions\n","\n","1. Execute the notebook to collect player data.\n","2. Review and analyze the SQL queries generated.\n","3. Integrate the SQL file into your preferred database for further analysis.\n","\n","Feel free to explore, modify, and adapt the code to suit your specific needs.\n","\n","---\n","\n","*Note: This notebook is for educational and personal project purposes only. All data is sourced from the official Premier League website.*\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-17T14:06:00.926614Z","iopub.status.busy":"2023-11-17T14:06:00.925673Z","iopub.status.idle":"2023-11-17T14:06:00.932379Z","shell.execute_reply":"2023-11-17T14:06:00.931194Z","shell.execute_reply.started":"2023-11-17T14:06:00.926542Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import plotly.express as px\n","import plotly.figure_factory as ff\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import math"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-11-17T14:06:00.935665Z","iopub.status.busy":"2023-11-17T14:06:00.935115Z","iopub.status.idle":"2023-11-17T14:06:00.990313Z","shell.execute_reply":"2023-11-17T14:06:00.989057Z","shell.execute_reply.started":"2023-11-17T14:06:00.935592Z"},"trusted":true},"outputs":[],"source":["log = pd.DataFrame(pd.read_csv(\"/kaggle/input/fantasy-premier-league-dataset-2023-2024/players.csv\"))\n","log.sample(5)"]},{"cell_type":"markdown","metadata":{},"source":["# **Team in 23/24**"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-17T14:06:00.992729Z","iopub.status.busy":"2023-11-17T14:06:00.992150Z","iopub.status.idle":"2023-11-17T14:06:01.000975Z","shell.execute_reply":"2023-11-17T14:06:00.999708Z","shell.execute_reply.started":"2023-11-17T14:06:00.992696Z"},"trusted":true},"outputs":[],"source":["team = log[\"team\"].values\n","All_team = np.unique(team)\n","All_team"]},{"cell_type":"markdown","metadata":{},"source":["# **Team Stadium**"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.execute_input":"2023-11-17T14:06:01.003658Z","iopub.status.busy":"2023-11-17T14:06:01.002798Z","iopub.status.idle":"2023-11-17T14:06:01.017718Z","shell.execute_reply":"2023-11-17T14:06:01.016652Z","shell.execute_reply.started":"2023-11-17T14:06:01.003576Z"},"trusted":true},"outputs":[],"source":["text = open(\"/kaggle/input/team-stadium/Team_Stadium.txt\").read()\n","# Split the string into lines\n","# lines = teams_and_stadiums.strip().split('\\n')\n","\n","# # Create the mapping dictionary\n","# # lines.remove('')\n","# mapping_dict = dict(zip(lines[0::2], lines[1::2]))\n","\n","# # Print the mapping dictionary\n","# print(mapping_dict)\n","\n","lines = [line.strip() for line in text.strip().split('\\n') if line.strip()]\n","team_stadium_list = [(lines[i], lines[i + 1]) for i in range(0, len(lines), 2)]\n","team_stadium = np.array(team_stadium_list)\n","\n","team_stadium[:5]"]},{"cell_type":"markdown","metadata":{},"source":["# **Get only played Team Stadium**"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-17T14:06:01.021340Z","iopub.status.busy":"2023-11-17T14:06:01.020437Z","iopub.status.idle":"2023-11-17T14:06:01.037376Z","shell.execute_reply":"2023-11-17T14:06:01.036248Z","shell.execute_reply.started":"2023-11-17T14:06:01.021296Z"},"trusted":true},"outputs":[],"source":["# Drop unplayed team\n","df = pd.DataFrame(team_stadium)\n","# df = np.delete(df,3)\n","df = df.drop([2,3,4,5,6,8,12,13,15,17,20,21,22,23,24,29,31,33,34,35,36,38,39,40,41,42,43,45,46,48,49])\n","df"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-17T14:06:01.039224Z","iopub.status.busy":"2023-11-17T14:06:01.038849Z","iopub.status.idle":"2023-11-17T14:06:01.051674Z","shell.execute_reply":"2023-11-17T14:06:01.050479Z","shell.execute_reply.started":"2023-11-17T14:06:01.039191Z"},"trusted":true},"outputs":[],"source":["# Turn in to array\n","df = np.array(df)\n","print(df[:5])"]},{"cell_type":"markdown","metadata":{},"source":["# **Scraping player data**"]},{"cell_type":"markdown","metadata":{},"source":["# Get all player"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-17T14:06:01.053817Z","iopub.status.busy":"2023-11-17T14:06:01.052983Z","iopub.status.idle":"2023-11-17T14:06:01.268094Z","shell.execute_reply":"2023-11-17T14:06:01.266614Z","shell.execute_reply.started":"2023-11-17T14:06:01.053781Z"},"trusted":true},"outputs":[],"source":["import requests\n","from bs4 import BeautifulSoup\n","\n","# Function to extract team ID from the given URL\n","def extract_team_id(url):\n","    # Extract team ID from the URL\n","    team_id = url.split('/')[2]\n","    return team_id\n","\n","# URL of the page containing club information\n","url = \"https://www.premierleague.com/clubs\"\n","\n","# Fetch the content of the page\n","response = requests.get(url)\n","soup = BeautifulSoup(response.content, 'html.parser')\n","\n","# Extract team IDs from each club card\n","club_cards = soup.find_all('li', class_='club-card-wrapper')\n","team_ids = [extract_team_id(club_card.find('a')['href']) for club_card in club_cards]\n","\n","# Display the list of team IDs\n","team_info = np.column_stack((df, team_ids))\n","team_info"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-17T14:22:16.927043Z","iopub.status.busy":"2023-11-17T14:22:16.926294Z","iopub.status.idle":"2023-11-17T14:26:11.737290Z","shell.execute_reply":"2023-11-17T14:26:11.736006Z","shell.execute_reply.started":"2023-11-17T14:22:16.926927Z"},"trusted":true},"outputs":[],"source":["import bs4\n","import requests\n","from datetime import datetime\n","\n","# Create a file to write the SQL queries\n","with open('/kaggle/working/insert_player.sql', 'a') as file:\n","    # Iterate through teams\n","    for i in range(0, team_info.shape[0]):\n","        url = f\"https://www.premierleague.com/clubs/{team_info[i][2]}/club/squad?se=578\"\n","        response = requests.get(url)\n","        soup = bs4.BeautifulSoup(response.text, 'html.parser')\n","        pl = []\n","\n","        # Find all player information cards\n","        player_cards = soup.find_all('li', class_='stats-card')\n","\n","        # Function to extract date of birth from player's overview page and convert it to the desired format\n","        def get_date_of_birth(player_url):\n","            player_page = requests.get(f\"https://www.premierleague.com{player_url}\")\n","            player_soup = bs4.BeautifulSoup(player_page.text, 'html.parser')\n","\n","            # Find the div with label \"Date of Birth\" and extract the date\n","            dob_element = player_soup.find('div', {'class': 'player-overview__label'}, string='Date of Birth')\n","            if dob_element:\n","                dob_text = dob_element.find_next('div', {'class': 'player-overview__info'}).get_text(strip=True)\n","                # Parse the date string and format it\n","                dob_date = datetime.strptime(dob_text.split('(')[0].strip(), '%d/%m/%Y').strftime('%Y-%m-%d')\n","            else:\n","                dob_date = ''\n","\n","            return dob_date\n","\n","        # Iterate through each player card and extract information\n","        for card in player_cards:\n","            name_first_element = card.select_one('.stats-card__player-first')\n","            name_last_element = card.select_one('.stats-card__player-last')\n","            position_element = card.select_one('.stats-card__player-position')\n","            squad_number_element = card.select_one('.stats-card__squad-number')\n","            player_url = card.select_one('.stats-card__wrapper')['href']\n","\n","            # Check if elements exist before extracting text\n","            name_first = name_first_element.get_text(strip=True) if name_first_element else ''\n","            name_last = name_last_element.get_text(strip=True) if name_last_element else ''\n","            position = position_element.get_text(strip=True) if position_element else ''\n","            squad_number = squad_number_element.get_text(strip=True) if squad_number_element else ''\n","\n","            # Escape single quotes in names\n","            name_first = name_first.replace(\"'\", \"''\")\n","            name_last = name_last.replace(\"'\", \"''\")\n","\n","            # Extract date of birth using the function\n","            dob = get_date_of_birth(player_url)\n","\n","            pl.append([name_first, name_last, position, squad_number, dob])\n","\n","        # SQL Insertion\n","        # Team ID\n","        team_id = i + 1\n","\n","        # Generate a single SQL INSERT statement for all players\n","        sql_query = (\n","            \"INSERT INTO `player` \"\n","            \"(`firstName`, `middleName`, `lastName`, \"\n","            \"`shirtNo`, `birthDate`, `position`, `isBanned`, \"\n","            \"`isInjured`, `teamID`)\\n\"\n","            \"VALUES \"\n","        )\n","\n","        # Add values for each player\n","        for player_info in pl:\n","            sql_query += \"('{}', NULL, '{}', '{}', '{}', '{}', NULL, NULL, '{}'), \".format(\n","                player_info[0], player_info[1], player_info[3], player_info[4], player_info[2], team_id\n","            )\n","\n","        # Remove the trailing comma and write the SQL query to the file\n","        sql_query = sql_query.rstrip(', ')\n","        file.write(sql_query + ';\\n')\n"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":4010536,"sourceId":6979173,"sourceType":"datasetVersion"},{"datasetId":3532653,"sourceId":6983565,"sourceType":"datasetVersion"}],"dockerImageVersionId":30579,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
