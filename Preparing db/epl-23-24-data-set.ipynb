{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":6979173,"sourceType":"datasetVersion","datasetId":4010536},{"sourceId":6983565,"sourceType":"datasetVersion","datasetId":3532653}],"dockerImageVersionId":30579,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# EPL 23/34 Player Dataset\n\nThis notebook is created for study and as part of a personal project related to the English Premier League (EPL).\n\n## Overview\n\nThe dataset provided in this notebook includes information on players who participated in EPL 23/34. The data is formatted as an SQL file for easy integration into databases.\n\n## Data Source\n\nThe data is collected from the official [Premier League website](https://www.premierleague.com/), a reliable source for up-to-date information on EPL teams and players.\n\n## Purpose\n\nThe primary goals of this notebook are:\n\n1. **Study**: Understand and analyze player data in the context of the EPL 23/34 season.\n2. **Personal Project**: Contribute to a personal project related to the English Premier League.\n\n## Contents\n\n- **Data Collection**: Player information is scraped from the Premier League website, including details such as name, position, date of birth, and team affiliation.\n- **SQL Format**: The collected data is formatted into SQL queries for easy integration into database systems.\n\n## Instructions\n\n1. Execute the notebook to collect player data.\n2. Review and analyze the SQL queries generated.\n3. Integrate the SQL file into your preferred database for further analysis.\n\nFeel free to explore, modify, and adapt the code to suit your specific needs.\n\n---\n\n*Note: This notebook is for educational and personal project purposes only. All data is sourced from the official Premier League website.*\n\n","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport plotly.express as px\nimport plotly.figure_factory as ff\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport math","metadata":{"execution":{"iopub.status.busy":"2023-11-17T14:06:00.925673Z","iopub.execute_input":"2023-11-17T14:06:00.926614Z","iopub.status.idle":"2023-11-17T14:06:00.932379Z","shell.execute_reply.started":"2023-11-17T14:06:00.926542Z","shell.execute_reply":"2023-11-17T14:06:00.931194Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"log = pd.DataFrame(pd.read_csv(\"/kaggle/input/fantasy-premier-league-dataset-2023-2024/players.csv\"))\nlog.sample(5)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-17T14:06:00.935115Z","iopub.execute_input":"2023-11-17T14:06:00.935665Z","iopub.status.idle":"2023-11-17T14:06:00.990313Z","shell.execute_reply.started":"2023-11-17T14:06:00.935592Z","shell.execute_reply":"2023-11-17T14:06:00.989057Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Team in 23/24**","metadata":{}},{"cell_type":"code","source":"team = log[\"team\"].values\nAll_team = np.unique(team)\nAll_team","metadata":{"execution":{"iopub.status.busy":"2023-11-17T14:06:00.992150Z","iopub.execute_input":"2023-11-17T14:06:00.992729Z","iopub.status.idle":"2023-11-17T14:06:01.000975Z","shell.execute_reply.started":"2023-11-17T14:06:00.992696Z","shell.execute_reply":"2023-11-17T14:06:00.999708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Team Stadium**","metadata":{}},{"cell_type":"code","source":"text = open(\"/kaggle/input/team-stadium/Team_Stadium.txt\").read()\n# Split the string into lines\n# lines = teams_and_stadiums.strip().split('\\n')\n\n# # Create the mapping dictionary\n# # lines.remove('')\n# mapping_dict = dict(zip(lines[0::2], lines[1::2]))\n\n# # Print the mapping dictionary\n# print(mapping_dict)\n\nlines = [line.strip() for line in text.strip().split('\\n') if line.strip()]\nteam_stadium_list = [(lines[i], lines[i + 1]) for i in range(0, len(lines), 2)]\nteam_stadium = np.array(team_stadium_list)\n\nteam_stadium[:5]","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-11-17T14:06:01.002798Z","iopub.execute_input":"2023-11-17T14:06:01.003658Z","iopub.status.idle":"2023-11-17T14:06:01.017718Z","shell.execute_reply.started":"2023-11-17T14:06:01.003576Z","shell.execute_reply":"2023-11-17T14:06:01.016652Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Get only played Team Stadium**","metadata":{}},{"cell_type":"code","source":"# Drop unplayed team\ndf = pd.DataFrame(team_stadium)\n# df = np.delete(df,3)\ndf = df.drop([2,3,4,5,6,8,12,13,15,17,20,21,22,23,24,29,31,33,34,35,36,38,39,40,41,42,43,45,46,48,49])\ndf","metadata":{"execution":{"iopub.status.busy":"2023-11-17T14:06:01.020437Z","iopub.execute_input":"2023-11-17T14:06:01.021340Z","iopub.status.idle":"2023-11-17T14:06:01.037376Z","shell.execute_reply.started":"2023-11-17T14:06:01.021296Z","shell.execute_reply":"2023-11-17T14:06:01.036248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Turn in to array\ndf = np.array(df)\nprint(df[:5])","metadata":{"execution":{"iopub.status.busy":"2023-11-17T14:06:01.038849Z","iopub.execute_input":"2023-11-17T14:06:01.039224Z","iopub.status.idle":"2023-11-17T14:06:01.051674Z","shell.execute_reply.started":"2023-11-17T14:06:01.039191Z","shell.execute_reply":"2023-11-17T14:06:01.050479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Scraping player data**","metadata":{}},{"cell_type":"markdown","source":"# Get all player","metadata":{}},{"cell_type":"code","source":"import requests\nfrom bs4 import BeautifulSoup\n\n# Function to extract team ID from the given URL\ndef extract_team_id(url):\n    # Extract team ID from the URL\n    team_id = url.split('/')[2]\n    return team_id\n\n# URL of the page containing club information\nurl = \"https://www.premierleague.com/clubs\"\n\n# Fetch the content of the page\nresponse = requests.get(url)\nsoup = BeautifulSoup(response.content, 'html.parser')\n\n# Extract team IDs from each club card\nclub_cards = soup.find_all('li', class_='club-card-wrapper')\nteam_ids = [extract_team_id(club_card.find('a')['href']) for club_card in club_cards]\n\n# Display the list of team IDs\nteam_info = np.column_stack((df, team_ids))\nteam_info","metadata":{"execution":{"iopub.status.busy":"2023-11-17T14:06:01.052983Z","iopub.execute_input":"2023-11-17T14:06:01.053817Z","iopub.status.idle":"2023-11-17T14:06:01.268094Z","shell.execute_reply.started":"2023-11-17T14:06:01.053781Z","shell.execute_reply":"2023-11-17T14:06:01.266614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import bs4\nimport requests\nfrom datetime import datetime\n\n# Create a file to write the SQL queries\nwith open('/kaggle/working/insert_player.sql', 'a') as file:\n    # Iterate through teams\n    for i in range(0, team_info.shape[0]):\n        url = f\"https://www.premierleague.com/clubs/{team_info[i][2]}/club/squad?se=578\"\n        response = requests.get(url)\n        soup = bs4.BeautifulSoup(response.text, 'html.parser')\n        pl = []\n\n        # Find all player information cards\n        player_cards = soup.find_all('li', class_='stats-card')\n\n        # Function to extract date of birth from player's overview page and convert it to the desired format\n        def get_date_of_birth(player_url):\n            player_page = requests.get(f\"https://www.premierleague.com{player_url}\")\n            player_soup = bs4.BeautifulSoup(player_page.text, 'html.parser')\n\n            # Find the div with label \"Date of Birth\" and extract the date\n            dob_element = player_soup.find('div', {'class': 'player-overview__label'}, string='Date of Birth')\n            if dob_element:\n                dob_text = dob_element.find_next('div', {'class': 'player-overview__info'}).get_text(strip=True)\n                # Parse the date string and format it\n                dob_date = datetime.strptime(dob_text.split('(')[0].strip(), '%d/%m/%Y').strftime('%Y-%m-%d')\n            else:\n                dob_date = ''\n\n            return dob_date\n\n        # Iterate through each player card and extract information\n        for card in player_cards:\n            name_first_element = card.select_one('.stats-card__player-first')\n            name_last_element = card.select_one('.stats-card__player-last')\n            position_element = card.select_one('.stats-card__player-position')\n            squad_number_element = card.select_one('.stats-card__squad-number')\n            player_url = card.select_one('.stats-card__wrapper')['href']\n\n            # Check if elements exist before extracting text\n            name_first = name_first_element.get_text(strip=True) if name_first_element else ''\n            name_last = name_last_element.get_text(strip=True) if name_last_element else ''\n            position = position_element.get_text(strip=True) if position_element else ''\n            squad_number = squad_number_element.get_text(strip=True) if squad_number_element else ''\n\n            # Escape single quotes in names\n            name_first = name_first.replace(\"'\", \"''\")\n            name_last = name_last.replace(\"'\", \"''\")\n\n            # Extract date of birth using the function\n            dob = get_date_of_birth(player_url)\n\n            pl.append([name_first, name_last, position, squad_number, dob])\n\n        # SQL Insertion\n        # Team ID\n        team_id = i + 1\n\n        # Generate a single SQL INSERT statement for all players\n        sql_query = (\n            \"INSERT INTO `player` \"\n            \"(`firstName`, `middleName`, `lastName`, \"\n            \"`shirtNo`, `birthDate`, `position`, `isBanned`, \"\n            \"`isInjured`, `teamID`)\\n\"\n            \"VALUES \"\n        )\n\n        # Add values for each player\n        for player_info in pl:\n            sql_query += \"('{}', NULL, '{}', '{}', '{}', '{}', NULL, NULL, '{}'), \".format(\n                player_info[0], player_info[1], player_info[3], player_info[4], player_info[2], team_id\n            )\n\n        # Remove the trailing comma and write the SQL query to the file\n        sql_query = sql_query.rstrip(', ')\n        file.write(sql_query + ';\\n')\n#         print(sql_query)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-17T14:22:16.926294Z","iopub.execute_input":"2023-11-17T14:22:16.927043Z","iopub.status.idle":"2023-11-17T14:26:11.737290Z","shell.execute_reply.started":"2023-11-17T14:22:16.926927Z","shell.execute_reply":"2023-11-17T14:26:11.736006Z"},"trusted":true},"execution_count":null,"outputs":[]}]}